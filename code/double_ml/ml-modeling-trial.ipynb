{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double ML - trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "from matplotlib.pyplot import hist\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for numpy\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe\n",
    "df = pd.read_csv('df_mix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>t</th>\n",
       "      <th>onset2COWCS</th>\n",
       "      <th>decade</th>\n",
       "      <th>democracy</th>\n",
       "      <th>logmountain</th>\n",
       "      <th>ethnic_fractionalization</th>\n",
       "      <th>religion_fractionalization</th>\n",
       "      <th>language_fractionalization</th>\n",
       "      <th>leg_british</th>\n",
       "      <th>...</th>\n",
       "      <th>ecgrowth_demeaned</th>\n",
       "      <th>treat_agri</th>\n",
       "      <th>treat_mine</th>\n",
       "      <th>treat_fuel</th>\n",
       "      <th>treat_metal</th>\n",
       "      <th>iv_transport</th>\n",
       "      <th>iv_agri</th>\n",
       "      <th>iv_mine</th>\n",
       "      <th>iv_fuel</th>\n",
       "      <th>iv_metal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.041836</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGO</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALB</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>WSM</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>YEM</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.033032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>ZAF</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>-0.016094</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3258 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country     t  onset2COWCS  decade  democracy  logmountain  \\\n",
       "0        ABW  1991          0.0     7.0        NaN          NaN   \n",
       "1        AFG  1991          NaN     7.0     0.0010     0.041836   \n",
       "2        AGO  1991          NaN     7.0     0.0035     0.022721   \n",
       "3        ALB  1991          0.0     7.0     0.0055          NaN   \n",
       "4        AND  1991          0.0     7.0        NaN          NaN   \n",
       "...      ...   ...          ...     ...        ...          ...   \n",
       "3253     WSM  2008          NaN     8.0        NaN          NaN   \n",
       "3254     YEM  2008          NaN     8.0     0.0040     0.033032   \n",
       "3255     ZAF  2008          NaN     8.0     0.0095     0.020412   \n",
       "3256     ZMB  2008          NaN     8.0     0.0085    -0.016094   \n",
       "3257     ZWE  2008          NaN     8.0     0.0030     0.010647   \n",
       "\n",
       "      ethnic_fractionalization  religion_fractionalization  \\\n",
       "0                          NaN                    0.004107   \n",
       "1                     0.007693                    0.002717   \n",
       "2                     0.007867                    0.006276   \n",
       "3                     0.002204                    0.004719   \n",
       "4                     0.007139                    0.002326   \n",
       "...                        ...                         ...   \n",
       "3253                  0.001376                    0.007871   \n",
       "3254                       NaN                    0.000023   \n",
       "3255                  0.007517                    0.008603   \n",
       "3256                  0.007808                    0.007359   \n",
       "3257                  0.003874                    0.007363   \n",
       "\n",
       "      language_fractionalization  leg_british  ...  ecgrowth_demeaned  \\\n",
       "0                       0.003889          NaN  ...                NaN   \n",
       "1                       0.006141         0.00  ...          -0.013176   \n",
       "2                       0.007870         0.00  ...          -0.029495   \n",
       "3                       0.000399         0.00  ...          -0.316090   \n",
       "4                       0.006848          NaN  ...                NaN   \n",
       "...                          ...          ...  ...                ...   \n",
       "3253                    0.000111          NaN  ...                NaN   \n",
       "3254                    0.000080          NaN  ...          -0.018882   \n",
       "3255                    0.008652         0.01  ...           0.010913   \n",
       "3256                    0.008734         0.01  ...           0.034775   \n",
       "3257                    0.004472         0.01  ...          -0.138130   \n",
       "\n",
       "      treat_agri  treat_mine  treat_fuel  treat_metal  iv_transport  iv_agri  \\\n",
       "0            0.0         1.0         1.0          1.0           0.0      NaN   \n",
       "1            NaN         1.0         NaN          1.0           NaN      NaN   \n",
       "2            NaN         0.0         NaN          1.0           0.0      NaN   \n",
       "3            0.0         1.0         1.0          1.0           NaN      NaN   \n",
       "4            0.0         0.0         NaN          NaN           0.0      NaN   \n",
       "...          ...         ...         ...          ...           ...      ...   \n",
       "3253         0.0         1.0         NaN          NaN           1.0      NaN   \n",
       "3254         NaN         NaN         NaN          NaN           1.0      NaN   \n",
       "3255         1.0         1.0         1.0          1.0           1.0      NaN   \n",
       "3256         0.0         0.0         0.0          0.0           0.0      NaN   \n",
       "3257         0.0         1.0         0.0          0.0           1.0      NaN   \n",
       "\n",
       "      iv_mine  iv_fuel  iv_metal  \n",
       "0         0.0      0.0       NaN  \n",
       "1         0.0      0.0       NaN  \n",
       "2         0.0      0.0       NaN  \n",
       "3         0.0      0.0       NaN  \n",
       "4         0.0      0.0       NaN  \n",
       "...       ...      ...       ...  \n",
       "3253      1.0      NaN       NaN  \n",
       "3254      1.0      NaN       NaN  \n",
       "3255      1.0      NaN       NaN  \n",
       "3256      1.0      NaN       NaN  \n",
       "3257      1.0      NaN       NaN  \n",
       "\n",
       "[3258 rows x 24 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 't', 'onset2COWCS', 'decade', 'democracy', 'logmountain',\n",
       "       'ethnic_fractionalization', 'religion_fractionalization',\n",
       "       'language_fractionalization', 'leg_british', 'opec', 'logpop_M_diff',\n",
       "       'logpopdens_diff', 'logoutreg_diff', 'ecgrowth_demeaned', 'treat_agri',\n",
       "       'treat_mine', 'treat_fuel', 'treat_metal', 'iv_transport', 'iv_agri',\n",
       "       'iv_mine', 'iv_fuel', 'iv_metal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_l = ['onset2COWCS']\n",
    "treatment_l = ['treat_fuel']\n",
    "instrument_l = ['iv_transport']\n",
    "block_l = ['decade', 'democracy', 'logmountain',\n",
    "       'ethnic_fractionalization', 'religion_fractionalization',\n",
    "       'language_fractionalization', 'leg_british', 'opec', 'logpop_M_diff',\n",
    "       'logpopdens_diff', 'logoutreg_diff', 'ecgrowth_demeaned']\n",
    "df_1 = df[outcome_l+treatment_l+instrument_l+block_l]\n",
    "df_1 = df_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onset2COWCS', 'treat_fuel', 'iv_transport', 'decade', 'democracy',\n",
       "       'logmountain', 'ethnic_fractionalization', 'religion_fractionalization',\n",
       "       'language_fractionalization', 'leg_british', 'opec', 'logpop_M_diff',\n",
       "       'logpopdens_diff', 'logoutreg_diff', 'ecgrowth_demeaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = df_1[outcome_l].reset_index(drop=True).squeeze()\n",
    "\n",
    "treatment = df_1[treatment_l].reset_index(drop=True).squeeze()\n",
    "\n",
    "instrument = df_1[instrument_l].reset_index(drop=True).squeeze()\n",
    "\n",
    "block = df_1[block_l].reset_index(drop=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Nuisance Function Models\n",
    "\n",
    "The next step is to specify models for \n",
    "\n",
    "*   $\\mu(z,x)=\\mathbb{E}(Y|z,x)$\n",
    "*   $m(z,x) = P(A=1|z,x)$\n",
    "*   $p(x) = P(Z=1|x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross Entropy of fit model 0.2019811485082506\n",
      "Test Cross Entropy of no-covariate model 0.04554525600658528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# specify a model for mu(z,x)\n",
    "\n",
    "# make a function that returns a sklearn model for later use in k-folding\n",
    "def make_mu_model():\n",
    "  return KNeighborsClassifier(n_neighbors=300)\n",
    "  #return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=300, max_depth=None)\n",
    "  #return RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "mu_model = make_mu_model()\n",
    "\n",
    "# Sanity check that chosen model actually improves test error\n",
    "# A real analysis should give substantial attention to model selection and validation \n",
    "\n",
    "X_zx = df_1[instrument_l + block_l].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_zx, outcome, test_size=0.2)\n",
    "mu_model.fit(X_train, y_train)\n",
    "#y_pred = mu_model.predict_proba(X_test)[:,1]\n",
    "y_pred = mu_model.predict(X_test)\n",
    "\n",
    "test_ce=log_loss(y_test, y_pred)\n",
    "print(f\"Test Cross Entropy of fit model {test_ce}\") \n",
    "baseline_ce=log_loss(y_test, y_train.mean()*np.ones_like(y_test))\n",
    "print(f\"Test Cross Entropy of no-covariate model {baseline_ce}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CE of fit model 0.1965032179417111\n",
      "Test CE of no-covariate model 0.69334362891686\n"
     ]
    }
   ],
   "source": [
    "# specify a model for m(z,x)\n",
    "\n",
    "def make_m_model():\n",
    "  #return LogisticRegression(max_iter=1000, warm_start=True, random_state=RANDOM_SEED)\n",
    "  return RandomForestClassifier(n_estimators=200, max_depth=None)\n",
    "\n",
    "m_model = make_m_model()\n",
    "# Sanity check that chosen model actually improves test error\n",
    "# A real analysis should give substantial attention to model selection and validation \n",
    "\n",
    "X_train, X_test, a_train, a_test = train_test_split(X_zx, treatment, test_size=0.2)\n",
    "m_model.fit(X_train, a_train)\n",
    "a_pred = m_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_ce=log_loss(a_test, a_pred)\n",
    "print(f\"Test CE of fit model {test_ce}\") \n",
    "baseline_ce=log_loss(a_test, a_train.mean()*np.ones_like(a_test))\n",
    "print(f\"Test CE of no-covariate model {baseline_ce}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CE of fit model 0.678264221241016\n",
      "Test CE of no-covariate model 0.6943932907828287\n"
     ]
    }
   ],
   "source": [
    "def make_p_model():\n",
    "  return RandomForestClassifier(n_estimators=200, max_depth=5)\n",
    "\n",
    "p_model = make_p_model()\n",
    "# Sanity check that chosen model actually improves test error\n",
    "# A real analysis should give substantial attention to model selection and validation \n",
    "\n",
    "X_train, X_test, Z_train, Z_test = train_test_split(block, instrument, test_size=0.2)\n",
    "p_model.fit(X_train, Z_train)\n",
    "Z_pred = p_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_ce=log_loss(Z_test, Z_pred)\n",
    "print(f\"Test CE of fit model {test_ce}\") \n",
    "baseline_ce=log_loss(Z_test, Z_train.mean()*np.ones_like(Z_test))\n",
    "print(f\"Test CE of no-covariate model {baseline_ce}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross fitting to get predicted $\\hat{\\mu}$, $\\hat{m}$, $\\hat{p}$ for each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to implement the cross fitting\n",
    "\n",
    "def p_k_fold_fit_and_predict(make_model, X:pd.DataFrame, Z:np.array, n_splits:int):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the instrument Z. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    Z: array of instruments\n",
    "    n_splits: number of splits to use\n",
    "    \"\"\"\n",
    "    predictions = np.full_like(Z, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, Z):\n",
    "      X_train = X.loc[train_index]\n",
    "      Z_train = Z.loc[train_index]\n",
    "      g = make_model()\n",
    "      g.fit(X_train, Z_train)\n",
    "\n",
    "      # get predictions for split\n",
    "      predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def m_k_fold_fit_and_predict(make_model, X:pd.DataFrame, Z:np.array, A:np.array, n_splits:int):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    Z: array of instruments\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    \"\"\"\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_zx = X.copy()\n",
    "    X_zx[\"Z\"] = Z\n",
    "\n",
    "    # for predicting A under Z=1 / Z=0 status for each data point \n",
    "    X0 = X_zx.copy()\n",
    "    X0[\"Z\"] = 0\n",
    "    X1 = X_zx.copy()\n",
    "    X1[\"Z\"] = 1\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_zx, A):\n",
    "      X_train = X_zx.loc[train_index]\n",
    "      A_train = A.loc[train_index]\n",
    "      m = make_model()\n",
    "      m.fit(X_train, A_train)\n",
    "      predictions0[test_index] = m.predict_proba(X0.loc[test_index])[:,1]\n",
    "      predictions1[test_index] = m.predict_proba(X1.loc[test_index])[:,1]\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1\n",
    "\n",
    "def mu_k_fold_fit_and_predict(make_model, X:pd.DataFrame, Z:np.array, y:np.array, n_splits:int, output_type:str):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    Z: array of instruments\n",
    "    y: array of outcomes\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "\n",
    "    \"\"\"\n",
    "    predictions0 = np.full_like(y, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "      kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_zx = X.copy()\n",
    "    X_zx[\"Z\"] = Z\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_zx.copy()\n",
    "    X0[\"Z\"] = 0\n",
    "    X1 = X_zx.copy()\n",
    "    X1[\"Z\"] = 1\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_zx, y):\n",
    "      X_train = X_zx.loc[train_index]\n",
    "      y_train = y.loc[train_index]\n",
    "      mu = make_model()\n",
    "      mu.fit(X_train, y_train)\n",
    "\n",
    "      if output_type =='binary':\n",
    "        predictions0[test_index] = mu.predict_proba(X0.loc[test_index])[:, 1]\n",
    "        predictions1[test_index] = mu.predict_proba(X1.loc[test_index])[:, 1]\n",
    "      elif output_type == 'continuous':\n",
    "        predictions0[test_index] = mu.predict(X0.loc[test_index])\n",
    "        predictions1[test_index] = mu.predict(X1.loc[test_index])\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p_k_fold_fit_and_predict(make_p_model, X=block, Z=instrument, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0,m1= m_k_fold_fit_and_predict(make_m_model, X=block, Z=instrument, A=treatment, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.01347509, 0.01347509, 0.08085055, 0.20212637, 0.26950183,\n",
       "        0.55247874, 1.10495749, 1.95388824, 4.05600248, 3.247497  ]),\n",
       " array([0.1  , 0.187, 0.274, 0.361, 0.448, 0.535, 0.622, 0.709, 0.796,\n",
       "        0.883, 0.97 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check relevance\n",
    "from matplotlib.pyplot import hist\n",
    "hist(m1-m0, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0,mu1= mu_k_fold_fit_and_predict(make_mu_model, X=block, Z=instrument, y=outcome, n_splits=10, output_type=\"continuous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>m1</th>\n",
       "      <th>m0</th>\n",
       "      <th>Z</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.532358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.576594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          p  mu0  mu1     m1     m0    Z    A    Y\n",
       "0  0.479879  0.0  0.0  0.905  0.105  1.0  1.0  0.0\n",
       "1  0.532358  0.0  0.0  0.890  0.190  0.0  0.0  1.0\n",
       "2  0.302874  0.0  0.0  0.890  0.020  0.0  0.0  0.0\n",
       "3  0.576594  0.0  0.0  0.700  0.105  0.0  0.0  0.0\n",
       "4  0.629801  0.0  0.0  0.780  0.360  1.0  1.0  0.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_and_nuisance_estimates = pd.DataFrame({'p': p, 'mu0': mu0, 'mu1': mu1, 'm1': m1, 'm0': m0,\n",
    "                                            'Z': instrument, 'A': treatment, 'Y': outcome})\n",
    "data_and_nuisance_estimates.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine predicted values and data into estimate of LATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_estimator(mu1, mu0, m1, m0, p, Z, A, Y, prob = None):\n",
    "  '''\n",
    "  Estimator for LATE\n",
    "  '''\n",
    "  n = len(Y)\n",
    "  phi_zy = mu1 - mu0 + Z*(Y-mu1)/p - (1-Z)*(Y-mu0)/(1-p)\n",
    "  phi_za = m1 - m0 + Z*(A-m1)/p - (1-Z)*(A-m0)/(1-p)\n",
    "\n",
    "  tau_za = phi_za.mean()\n",
    "  tau_hat = phi_zy.mean()/tau_za\n",
    "  phi = phi_zy - phi_za * tau_hat\n",
    "  \n",
    "  std_hat = math.sqrt((phi**2).mean()/tau_za**2/n)\n",
    "\n",
    "  return tau_hat, std_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate is 0.025351559755204214 pm 0.023657876851726576\n"
     ]
    }
   ],
   "source": [
    "tau_hat, std_hat = late_estimator(**data_and_nuisance_estimates)\n",
    "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
