{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double ML - modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "from matplotlib.pyplot import hist\n",
    "import scipy.stats as stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for numpy\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_p(estimate, std):\n",
    "    z_value = estimate / std\n",
    "    p_value = stats.norm.sf(abs(z_value))*2\n",
    "    return round(estimate, 4), round(std, 4), round(p_value, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Specify Nuisance Function Models\n",
    "\n",
    "The next step is to specify models for \n",
    "\n",
    "*   $\\mu(z,x)=\\mathbb{E}(Y|z,x)$\n",
    "*   $m(z,x) = P(A=1|z,x)$\n",
    "*   $p(x) = P(Z=1|x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that returns a sklearn model for later use in k-folding\n",
    "def make_mu_model():\n",
    "  return KNeighborsClassifier(n_neighbors=300)\n",
    "  #return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=300, max_depth=None)\n",
    "  #return RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "\n",
    "# specify a model for m(z,x)\n",
    "def make_m_model():\n",
    "  #return LogisticRegression(max_iter=1000, warm_start=True, random_state=RANDOM_SEED)\n",
    "  return RandomForestClassifier(n_estimators=200, max_depth=None)\n",
    "\n",
    "def make_p_model():\n",
    "  return RandomForestClassifier(n_estimators=200, max_depth=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Functions that use cross fitting to get predicted $\\hat{\\mu}$, $\\hat{m}$, $\\hat{p}$ for each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to implement the cross fitting\n",
    "\n",
    "def p_k_fold_fit_and_predict(make_model, X:pd.DataFrame, Z:np.array, n_splits:int):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the instrument Z. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    Z: array of instruments\n",
    "    n_splits: number of splits to use\n",
    "    \"\"\"\n",
    "    predictions = np.full_like(Z, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, Z):\n",
    "      X_train = X.loc[train_index]\n",
    "      Z_train = Z.loc[train_index]\n",
    "      g = make_model()\n",
    "      g.fit(X_train, Z_train)\n",
    "\n",
    "      # get predictions for split\n",
    "      predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def m_k_fold_fit_and_predict(make_model, X:pd.DataFrame, Z:np.array, A:np.array, n_splits:int):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    Z: array of instruments\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    \"\"\"\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_zx = X.copy()\n",
    "    X_zx[\"Z\"] = Z\n",
    "\n",
    "    # for predicting A under Z=1 / Z=0 status for each data point \n",
    "    X0 = X_zx.copy()\n",
    "    X0[\"Z\"] = 0\n",
    "    X1 = X_zx.copy()\n",
    "    X1[\"Z\"] = 1\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_zx, A):\n",
    "      X_train = X_zx.loc[train_index]\n",
    "      A_train = A.loc[train_index]\n",
    "      m = make_model()\n",
    "      m.fit(X_train, A_train)\n",
    "      predictions0[test_index] = m.predict_proba(X0.loc[test_index])[:,1]\n",
    "      predictions1[test_index] = m.predict_proba(X1.loc[test_index])[:,1]\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1\n",
    "\n",
    "def mu_k_fold_fit_and_predict(make_model, X:pd.DataFrame, Z:np.array, y:np.array, n_splits:int, output_type:str):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    Z: array of instruments\n",
    "    y: array of outcomes\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "\n",
    "    \"\"\"\n",
    "    predictions0 = np.full_like(y, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "      kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_zx = X.copy()\n",
    "    X_zx[\"Z\"] = Z\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_zx.copy()\n",
    "    X0[\"Z\"] = 0\n",
    "    X1 = X_zx.copy()\n",
    "    X1[\"Z\"] = 1\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_zx, y):\n",
    "      X_train = X_zx.loc[train_index]\n",
    "      y_train = y.loc[train_index]\n",
    "      mu = make_model()\n",
    "      mu.fit(X_train, y_train)\n",
    "\n",
    "      if output_type =='binary':\n",
    "        predictions0[test_index] = mu.predict_proba(X0.loc[test_index])[:, 1]\n",
    "        predictions1[test_index] = mu.predict_proba(X1.loc[test_index])[:, 1]\n",
    "      elif output_type == 'continuous':\n",
    "        predictions0[test_index] = mu.predict(X0.loc[test_index])\n",
    "        predictions1[test_index] = mu.predict(X1.loc[test_index])\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 LATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_estimator(mu1, mu0, m1, m0, p, Z, A, Y, prob = None):\n",
    "  '''\n",
    "  Estimator for LATE\n",
    "  '''\n",
    "  n = len(Y)\n",
    "  phi_zy = mu1 - mu0 + Z*(Y-mu1)/p - (1-Z)*(Y-mu0)/(1-p)\n",
    "  phi_za = m1 - m0 + Z*(A-m1)/p - (1-Z)*(A-m0)/(1-p)\n",
    "\n",
    "  tau_za = phi_za.mean()\n",
    "  tau_hat = phi_zy.mean()/tau_za\n",
    "  phi = phi_zy - phi_za * tau_hat\n",
    "  \n",
    "  std_hat = math.sqrt((phi**2).mean()/tau_za**2/n)\n",
    "\n",
    "  return tau_hat, std_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Run a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df, outcome_l, treatment_l, instrument_l, block_l):\n",
    "\n",
    "    df_1 = df[outcome_l+treatment_l+instrument_l+block_l]\n",
    "    df_1 = df_1.dropna()\n",
    "\n",
    "    outcome = df_1[outcome_l].reset_index(drop=True).squeeze()\n",
    "    treatment = df_1[treatment_l].reset_index(drop=True).squeeze()\n",
    "    instrument = df_1[instrument_l].reset_index(drop=True).squeeze()\n",
    "    block = df_1[block_l].reset_index(drop=True)\n",
    "\n",
    "    p = p_k_fold_fit_and_predict(make_p_model, X=block, Z=instrument, n_splits=10)\n",
    "    m0,m1= m_k_fold_fit_and_predict(make_m_model, X=block, Z=instrument, A=treatment, n_splits=10)\n",
    "    mu0,mu1= mu_k_fold_fit_and_predict(make_mu_model, X=block, Z=instrument, y=outcome, n_splits=10, output_type=\"continuous\")\n",
    "    tau_hat, std_hat = late_estimator(mu1, mu0, m1, m0, p, Z=instrument, A=treatment, Y=outcome, prob = None)\n",
    "    \n",
    "    return find_p(tau_hat, std_hat)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 `df_mix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe\n",
    "df = pd.read_csv('df_mix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 't', 'onset2COWCS', 'decade', 'democracy', 'logmountain',\n",
       "       'ethnic_fractionalization', 'religion_fractionalization',\n",
       "       'language_fractionalization', 'leg_british', 'opec', 'logpop_M_diff',\n",
       "       'logpopdens_diff', 'logoutreg_diff', 'ecgrowth_demeaned', 'treat_agri',\n",
       "       'treat_mine', 'treat_fuel', 'treat_metal', 'iv_transport', 'iv_agri',\n",
       "       'iv_mine', 'iv_fuel', 'iv_metal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0255, 0.0122, 0.0365)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_l = ['onset2COWCS']\n",
    "treatment_l = ['treat_fuel']\n",
    "instrument_l = ['iv_transport']\n",
    "block_l = ['decade', 'democracy', 'logmountain',\n",
    "       'ethnic_fractionalization', 'religion_fractionalization',\n",
    "       'language_fractionalization', 'leg_british', 'opec', 'logpop_M_diff',\n",
    "       'logpopdens_diff', 'logoutreg_diff', 'ecgrowth_demeaned']\n",
    "\n",
    "run(df, outcome_l, treatment_l, instrument_l, block_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
